{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOKIH40gH2Uq"
      },
      "outputs": [],
      "source": [
        "#importing the required libraries\n",
        "import time\n",
        "import cv2\n",
        "import os, shutil\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import imutils\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from collections import OrderedDict\n",
        "from skimage import io, transform\n",
        "from math import *\n",
        "import xml.etree.ElementTree as ET \n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as TF\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6f0V8qXCpvb",
        "outputId": "d2a5dabf-2b2d-4d6c-bc9f-3550276e6d73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.6.11-py3-none-any.whl (548 kB)\n",
            "\u001b[K     |████████████████████████████████| 548 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from timm) (6.0)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 41.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.13.1+cu113)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from timm) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7->timm) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (5.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub->timm) (3.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (3.0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Installing collected packages: huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.10.1 timm-0.6.11\n"
          ]
        }
      ],
      "source": [
        "pip install timm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBn5JKtaMELN",
        "outputId": "573bcc05-8d70-47e1-9d6b-a359c3927ff8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv9L1EIDMp8f",
        "outputId": "7f5023c2-15df-44f6-ffd8-1ef17638db1c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'unzip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "os.mkdir('/dataset_1000')\n",
        "#unzipping and extracting the dataset\n",
        "!unzip /dataset_1000.zip -d '/dataset_1000'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dra_UM5_iw5k"
      },
      "outputs": [],
      "source": [
        "# return all files as a list\n",
        "landmarks_list = []\n",
        "for file in os.listdir('/Downloads/dataset_1000'):\n",
        "     # check the files which are end with specific extension\n",
        "    if file.endswith(\".txt\"):\n",
        "        # append path name of selected files\n",
        "        landmarks_list.append(file)\n",
        "os.mkdir('/Downloads/dataset_1000/landmarks')\n",
        "for f in landmarks_list:\n",
        "  file_path = os.path.join('/Downloads/dataset_1000', f)\n",
        "  shutil.move(file_path, '/Downloads/dataset_1000/landmarks')\n",
        "images_list = []\n",
        "for file in os.listdir('/Downloads/dataset_1000'):\n",
        "     # check the files which are end with specific extension\n",
        "    if file.endswith(\".png\"):\n",
        "      if file.endswith(\"seg.png\"):\n",
        "        pass\n",
        "      else:\n",
        "        # append path name of selected files\n",
        "        images_list.append(file)\n",
        "os.mkdir('/Downloads/dataset_1000/images')\n",
        "for f in images_list:\n",
        "  file_path = os.path.join('/Downloads/dataset_1000', f)\n",
        "  shutil.move(file_path, '/Downloads/dataset_1000/images')\n",
        "segmented_img_list = []\n",
        "for file in os.listdir('/Downloads/dataset_1000'):\n",
        "     # check the files which are end with specific extension\n",
        "    if file.endswith(\"seg.png\"):\n",
        "        # append path name of selected files\n",
        "        segmented_img_list.append(file)\n",
        "os.mkdir('/Downloads/dataset_1000/segmented_images')\n",
        "for f in segmented_img_list:\n",
        "  file_path = os.path.join('/Downloads/dataset_1000', f)\n",
        "  shutil.move(file_path, '/Downloads/dataset_1000/segmented_images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "YGTe9ICReViu",
        "outputId": "9af8ca9f-441b-4cac-830d-d6cb29968cb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "file = open('/content/gdrive/MyDrive/dataset_1000/landmarks/000000_ldmks.txt')\n",
        "points = file.readlines()[:]\n",
        "\n",
        "landmarks = []\n",
        "i =0 \n",
        "for point in points:\n",
        "  i+=1\n",
        "  x,y = point.split(' ')\n",
        "  landmarks.append([floor(float(x)), floor(float(y[:-1]))])\n",
        "print(i)\n",
        "landmarks = np.array(landmarks)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(mpimg.imread('/content/gdrive/MyDrive/dataset_1000/segmented_images/000000_seg.png'))\n",
        "plt.scatter(landmarks[:,0], landmarks[:,1], s = 5, c = 'g')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nu3AMFQTh-cY"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Transforms():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def rotate(self, image, landmarks, angle):\n",
        "        angle = random.uniform(-angle, +angle)\n",
        "\n",
        "        transformation_matrix = torch.tensor([\n",
        "            [+cos(radians(angle)), -sin(radians(angle))], \n",
        "            [+sin(radians(angle)), +cos(radians(angle))]\n",
        "        ])\n",
        "\n",
        "        image = imutils.rotate(np.array(image), angle)\n",
        "\n",
        "        landmarks = landmarks - 0.5\n",
        "        new_landmarks = np.matmul(landmarks, transformation_matrix)\n",
        "        new_landmarks = new_landmarks + 0.5\n",
        "        return Image.fromarray(image), new_landmarks\n",
        "\n",
        "    def resize(self, image, landmarks, img_size):\n",
        "        image = TF.resize(image, img_size)\n",
        "        return image, landmarks\n",
        "\n",
        "    def color_jitter(self, image, landmarks):\n",
        "        color_jitter = transforms.ColorJitter(brightness=0.3, \n",
        "                                              contrast=0.3,\n",
        "                                              saturation=0.3, \n",
        "                                              hue=0.1)\n",
        "        image = color_jitter(image)\n",
        "        return image, landmarks\n",
        "\n",
        "    def crop_face(self, image, landmarks, crops):\n",
        "        left = int(crops['left'])\n",
        "        top = int(crops['top'])\n",
        "        width = int(crops['width'])\n",
        "        height = int(crops['height'])\n",
        "\n",
        "        image = TF.crop(image, top, left, height, width)\n",
        "\n",
        "        img_shape = np.array(image).shape\n",
        "        landmarks = torch.tensor(landmarks) - torch.tensor([[left, top]])\n",
        "        landmarks = landmarks / torch.tensor([img_shape[1], img_shape[0]])\n",
        "        return image, landmarks\n",
        "\n",
        "    def __call__(self, image, landmarks, crops):\n",
        "        image = Image.fromarray(image)\n",
        "        image, landmarks = self.crop_face(image, landmarks, crops)\n",
        "        image, landmarks = self.resize(image, landmarks, (224, 224))\n",
        "        image, landmarks = self.color_jitter(image, landmarks)\n",
        "        image, landmarks = self.rotate(image, landmarks, angle=10)\n",
        "        \n",
        "        image = TF.to_tensor(image)\n",
        "        image = TF.normalize(image, [0.5], [0.5])\n",
        "        return image, landmarks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8qV-GcOm4a0"
      },
      "outputs": [],
      "source": [
        "class FaceLandmarksDataset(Dataset):\n",
        "\n",
        "    def __init__(self, transform=None):\n",
        "      self.image_filenames = []\n",
        "      self.landmarks = []\n",
        "      self.crops = []\n",
        "      self.transform = transform\n",
        "      path_landmarks = '/content/gdrive/MyDrive/dataset_1000/landmarks'\n",
        "      path_seg_imgs = '/content/gdrive/MyDrive/dataset_1000/segmented_images'\n",
        "      landmarks_filenames = sorted(os.listdir(path_landmarks))\n",
        "      segimg_filenames = sorted(os.listdir(path_seg_imgs))\n",
        "      for filename in landmarks_filenames:\n",
        "        file = open(os.path.join(path_landmarks, filename))\n",
        "        points = file.readlines()[:]\n",
        "        landmarks = []\n",
        "        for point in points:\n",
        "          x,y = point.split(' ')\n",
        "          landmarks.append([floor(float(x)), floor(float(y))])\n",
        "        self.landmarks.append(landmarks)\n",
        "      self.landmarks = np.array(self.landmarks).astype('float32') \n",
        "      for filename in segimg_filenames:\n",
        "        filepath = os.path.join(path_seg_imgs, filename)\n",
        "        img =   Image.open(filepath)\n",
        "        crop = {}\n",
        "        crop['width'] = img.width\n",
        "        crop['height'] = img.height\n",
        "        crop['top'] = 0\n",
        "        crop['left'] = 0\n",
        "        self.crops.append(crop)\n",
        "        self.image_filenames.append(os.path.join(path_seg_imgs, filename))\n",
        "      assert len(self.image_filenames) == len(self.landmarks)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = cv2.imread(self.image_filenames[index], 0)\n",
        "        landmarks = self.landmarks[index]\n",
        "        \n",
        "        if self.transform:\n",
        "            image, landmarks = self.transform(image, landmarks, self.crops[index])\n",
        "        landmarks = landmarks - 0.5\n",
        "        return image, landmarks\n",
        "\n",
        "dataset = FaceLandmarksDataset(Transforms())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "7zgbysC9xrPn",
        "outputId": "fae63663-bcde-4c52-8ca0-582e16b06ed8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "image, landmarks = dataset[256]\n",
        "landmarks = (landmarks + 0.5) * 224\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(image.numpy().squeeze(), cmap='gray');\n",
        "plt.scatter(landmarks[:,0], landmarks[:,1], s=8);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9PZ570k0GAZ",
        "outputId": "2e430f4f-5899-49c1-9bd7-aab4837e00df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of Train set is 900\n",
            "The length of Valid set is 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "# split the dataset into validation and test sets\n",
        "len_valid_set = int(0.1*len(dataset))\n",
        "len_train_set = len(dataset) - len_valid_set\n",
        "\n",
        "print(\"The length of Train set is {}\".format(len_train_set))\n",
        "print(\"The length of Valid set is {}\".format(len_valid_set))\n",
        "\n",
        "train_dataset , valid_dataset,  = torch.utils.data.random_split(dataset , [len_train_set, len_valid_set])\n",
        "\n",
        "# shuffle and batch the datasets\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=8, shuffle=True, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsC2h8Wf0TnC",
        "outputId": "b0aef2c3-89ba-4394-e577-d2ec1c8fe8df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 224, 224])\n",
            "torch.Size([64, 70, 2])\n"
          ]
        }
      ],
      "source": [
        "images, landmarks = next(iter(train_loader))\n",
        "\n",
        "print(images.shape)\n",
        "print(landmarks.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHDol9Jt0X_C"
      },
      "outputs": [],
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self,num_classes=140):\n",
        "        super().__init__()\n",
        "        self.model_name='resnet18'\n",
        "        self.model = timm.create_model('resnet101', pretrained = True, in_chans = 1)\n",
        "        self.model.conv1=nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.model.fc=nn.Linear(self.model.fc.in_features, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x=self.model(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJjgN0RR0fJ2"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "def print_overwrite(step, total_step, loss, operation):\n",
        "    sys.stdout.write('\\r')\n",
        "    if operation == 'train':\n",
        "        sys.stdout.write(\"Train Steps: %d/%d  Loss: %.4f \" % (step, total_step, loss))   \n",
        "    else:\n",
        "        sys.stdout.write(\"Valid Steps: %d/%d  Loss: %.4f \" % (step, total_step, loss))\n",
        "        \n",
        "    sys.stdout.flush()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykWEP88tuhK2",
        "outputId": "710c59f0-b623-426f-f22c-7688ac8a02cd"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rsb-weights/resnet101_a1h-36d3f2aa.pth\" to /root/.cache/torch/hub/checkpoints/resnet101_a1h-36d3f2aa.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Steps: 13/13  Loss: 0.0169 \n",
            "--------------------------------------------------\n",
            "Epoch: 1  Train Loss: 0.0211  Valid Loss: 0.0169\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0169 at epoch 1/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0128 \n",
            "--------------------------------------------------\n",
            "Epoch: 2  Train Loss: 0.0101  Valid Loss: 0.0128\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0128 at epoch 2/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0092 \n",
            "--------------------------------------------------\n",
            "Epoch: 3  Train Loss: 0.0080  Valid Loss: 0.0092\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0092 at epoch 3/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0082 \n",
            "--------------------------------------------------\n",
            "Epoch: 4  Train Loss: 0.0074  Valid Loss: 0.0082\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0082 at epoch 4/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0079 \n",
            "--------------------------------------------------\n",
            "Epoch: 5  Train Loss: 0.0071  Valid Loss: 0.0079\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0079 at epoch 5/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0076 \n",
            "--------------------------------------------------\n",
            "Epoch: 6  Train Loss: 0.0069  Valid Loss: 0.0076\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0076 at epoch 6/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0080 \n",
            "--------------------------------------------------\n",
            "Epoch: 7  Train Loss: 0.0069  Valid Loss: 0.0080\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0071 \n",
            "--------------------------------------------------\n",
            "Epoch: 8  Train Loss: 0.0067  Valid Loss: 0.0071\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0071 at epoch 8/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0065 \n",
            "--------------------------------------------------\n",
            "Epoch: 9  Train Loss: 0.0066  Valid Loss: 0.0065\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0065 at epoch 9/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0065 \n",
            "--------------------------------------------------\n",
            "Epoch: 10  Train Loss: 0.0064  Valid Loss: 0.0065\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0065 at epoch 10/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0062 \n",
            "--------------------------------------------------\n",
            "Epoch: 11  Train Loss: 0.0063  Valid Loss: 0.0062\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0062 at epoch 11/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0053 \n",
            "--------------------------------------------------\n",
            "Epoch: 12  Train Loss: 0.0060  Valid Loss: 0.0053\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0053 at epoch 12/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0054 \n",
            "--------------------------------------------------\n",
            "Epoch: 13  Train Loss: 0.0056  Valid Loss: 0.0054\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0055 \n",
            "--------------------------------------------------\n",
            "Epoch: 14  Train Loss: 0.0051  Valid Loss: 0.0055\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0044 \n",
            "--------------------------------------------------\n",
            "Epoch: 15  Train Loss: 0.0046  Valid Loss: 0.0044\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0044 at epoch 15/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0048 \n",
            "--------------------------------------------------\n",
            "Epoch: 16  Train Loss: 0.0045  Valid Loss: 0.0048\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0049 \n",
            "--------------------------------------------------\n",
            "Epoch: 17  Train Loss: 0.0038  Valid Loss: 0.0049\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0038 \n",
            "--------------------------------------------------\n",
            "Epoch: 18  Train Loss: 0.0037  Valid Loss: 0.0038\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0038 at epoch 18/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0038 \n",
            "--------------------------------------------------\n",
            "Epoch: 19  Train Loss: 0.0032  Valid Loss: 0.0038\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0037 \n",
            "--------------------------------------------------\n",
            "Epoch: 20  Train Loss: 0.0031  Valid Loss: 0.0037\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0037 at epoch 20/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0032 \n",
            "--------------------------------------------------\n",
            "Epoch: 21  Train Loss: 0.0030  Valid Loss: 0.0032\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0032 at epoch 21/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0032 \n",
            "--------------------------------------------------\n",
            "Epoch: 22  Train Loss: 0.0029  Valid Loss: 0.0032\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0032 at epoch 22/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0034 \n",
            "--------------------------------------------------\n",
            "Epoch: 23  Train Loss: 0.0027  Valid Loss: 0.0034\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0029 \n",
            "--------------------------------------------------\n",
            "Epoch: 24  Train Loss: 0.0026  Valid Loss: 0.0029\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0029 at epoch 24/200\n",
            "Model Saved\n",
            "\n",
            "Train Steps: 7/15  Loss: 0.0024 "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/util.py\", line 300, in _run_finalizers\n",
            "    finalizer()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/util.py\", line 224, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
            "    rmtree(tempdir)\n",
            "  File \"/usr/lib/python3.7/shutil.py\", line 498, in rmtree\n",
            "    onerror(os.rmdir, path, sys.exc_info())\n",
            "  File \"/usr/lib/python3.7/shutil.py\", line 496, in rmtree\n",
            "    os.rmdir(path)\n",
            "OSError: [Errno 39] Directory not empty: '/tmp/pymp-38n96upt'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Steps: 13/13  Loss: 0.0029 \n",
            "--------------------------------------------------\n",
            "Epoch: 25  Train Loss: 0.0025  Valid Loss: 0.0029\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0026 \n",
            "--------------------------------------------------\n",
            "Epoch: 26  Train Loss: 0.0024  Valid Loss: 0.0026\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0026 at epoch 26/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0023 \n",
            "--------------------------------------------------\n",
            "Epoch: 27  Train Loss: 0.0022  Valid Loss: 0.0023\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0023 at epoch 27/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0029 \n",
            "--------------------------------------------------\n",
            "Epoch: 28  Train Loss: 0.0022  Valid Loss: 0.0029\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0023 \n",
            "--------------------------------------------------\n",
            "Epoch: 29  Train Loss: 0.0022  Valid Loss: 0.0023\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0023 at epoch 29/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0027 \n",
            "--------------------------------------------------\n",
            "Epoch: 30  Train Loss: 0.0020  Valid Loss: 0.0027\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0027 \n",
            "--------------------------------------------------\n",
            "Epoch: 31  Train Loss: 0.0019  Valid Loss: 0.0027\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0024 \n",
            "--------------------------------------------------\n",
            "Epoch: 32  Train Loss: 0.0020  Valid Loss: 0.0024\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0023 \n",
            "--------------------------------------------------\n",
            "Epoch: 33  Train Loss: 0.0018  Valid Loss: 0.0023\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0023 at epoch 33/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0021 \n",
            "--------------------------------------------------\n",
            "Epoch: 34  Train Loss: 0.0019  Valid Loss: 0.0021\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0021 at epoch 34/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0022 \n",
            "--------------------------------------------------\n",
            "Epoch: 35  Train Loss: 0.0017  Valid Loss: 0.0022\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0024 \n",
            "--------------------------------------------------\n",
            "Epoch: 36  Train Loss: 0.0016  Valid Loss: 0.0024\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0023 \n",
            "--------------------------------------------------\n",
            "Epoch: 37  Train Loss: 0.0017  Valid Loss: 0.0023\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0024 \n",
            "--------------------------------------------------\n",
            "Epoch: 38  Train Loss: 0.0016  Valid Loss: 0.0024\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0020 \n",
            "--------------------------------------------------\n",
            "Epoch: 39  Train Loss: 0.0014  Valid Loss: 0.0020\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0020 at epoch 39/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0019 \n",
            "--------------------------------------------------\n",
            "Epoch: 40  Train Loss: 0.0015  Valid Loss: 0.0019\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0019 at epoch 40/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0017 \n",
            "--------------------------------------------------\n",
            "Epoch: 41  Train Loss: 0.0015  Valid Loss: 0.0017\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0017 at epoch 41/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0019 \n",
            "--------------------------------------------------\n",
            "Epoch: 42  Train Loss: 0.0015  Valid Loss: 0.0019\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0019 \n",
            "--------------------------------------------------\n",
            "Epoch: 43  Train Loss: 0.0014  Valid Loss: 0.0019\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0018 \n",
            "--------------------------------------------------\n",
            "Epoch: 44  Train Loss: 0.0014  Valid Loss: 0.0018\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0015 \n",
            "--------------------------------------------------\n",
            "Epoch: 45  Train Loss: 0.0013  Valid Loss: 0.0015\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0015 at epoch 45/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0021 \n",
            "--------------------------------------------------\n",
            "Epoch: 46  Train Loss: 0.0014  Valid Loss: 0.0021\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0019 \n",
            "--------------------------------------------------\n",
            "Epoch: 47  Train Loss: 0.0013  Valid Loss: 0.0019\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0016 \n",
            "--------------------------------------------------\n",
            "Epoch: 48  Train Loss: 0.0013  Valid Loss: 0.0016\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0015 \n",
            "--------------------------------------------------\n",
            "Epoch: 49  Train Loss: 0.0011  Valid Loss: 0.0015\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0015 at epoch 49/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0016 \n",
            "--------------------------------------------------\n",
            "Epoch: 50  Train Loss: 0.0012  Valid Loss: 0.0016\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0016 \n",
            "--------------------------------------------------\n",
            "Epoch: 51  Train Loss: 0.0011  Valid Loss: 0.0016\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0014 \n",
            "--------------------------------------------------\n",
            "Epoch: 52  Train Loss: 0.0011  Valid Loss: 0.0014\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0014 at epoch 52/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0014 \n",
            "--------------------------------------------------\n",
            "Epoch: 53  Train Loss: 0.0011  Valid Loss: 0.0014\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0014 \n",
            "--------------------------------------------------\n",
            "Epoch: 54  Train Loss: 0.0011  Valid Loss: 0.0014\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0014 at epoch 54/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0014 \n",
            "--------------------------------------------------\n",
            "Epoch: 55  Train Loss: 0.0010  Valid Loss: 0.0014\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0014 at epoch 55/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0013 \n",
            "--------------------------------------------------\n",
            "Epoch: 56  Train Loss: 0.0011  Valid Loss: 0.0013\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0013 at epoch 56/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0014 \n",
            "--------------------------------------------------\n",
            "Epoch: 57  Train Loss: 0.0010  Valid Loss: 0.0014\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0013 \n",
            "--------------------------------------------------\n",
            "Epoch: 58  Train Loss: 0.0010  Valid Loss: 0.0013\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0013 \n",
            "--------------------------------------------------\n",
            "Epoch: 59  Train Loss: 0.0009  Valid Loss: 0.0013\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0011 \n",
            "--------------------------------------------------\n",
            "Epoch: 60  Train Loss: 0.0009  Valid Loss: 0.0011\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0011 at epoch 60/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0013 \n",
            "--------------------------------------------------\n",
            "Epoch: 61  Train Loss: 0.0009  Valid Loss: 0.0013\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0012 \n",
            "--------------------------------------------------\n",
            "Epoch: 62  Train Loss: 0.0009  Valid Loss: 0.0012\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0014 \n",
            "--------------------------------------------------\n",
            "Epoch: 63  Train Loss: 0.0009  Valid Loss: 0.0014\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0011 \n",
            "--------------------------------------------------\n",
            "Epoch: 64  Train Loss: 0.0008  Valid Loss: 0.0011\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0011 at epoch 64/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0012 \n",
            "--------------------------------------------------\n",
            "Epoch: 65  Train Loss: 0.0008  Valid Loss: 0.0012\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0013 \n",
            "--------------------------------------------------\n",
            "Epoch: 66  Train Loss: 0.0008  Valid Loss: 0.0013\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0013 \n",
            "--------------------------------------------------\n",
            "Epoch: 67  Train Loss: 0.0009  Valid Loss: 0.0013\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0011 \n",
            "--------------------------------------------------\n",
            "Epoch: 68  Train Loss: 0.0008  Valid Loss: 0.0011\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0011 at epoch 68/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0009 \n",
            "--------------------------------------------------\n",
            "Epoch: 69  Train Loss: 0.0008  Valid Loss: 0.0009\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0009 at epoch 69/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0010 \n",
            "--------------------------------------------------\n",
            "Epoch: 70  Train Loss: 0.0008  Valid Loss: 0.0010\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0012 \n",
            "--------------------------------------------------\n",
            "Epoch: 71  Train Loss: 0.0008  Valid Loss: 0.0012\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0012 \n",
            "--------------------------------------------------\n",
            "Epoch: 72  Train Loss: 0.0008  Valid Loss: 0.0012\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0010 \n",
            "--------------------------------------------------\n",
            "Epoch: 73  Train Loss: 0.0007  Valid Loss: 0.0010\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0010 \n",
            "--------------------------------------------------\n",
            "Epoch: 74  Train Loss: 0.0008  Valid Loss: 0.0010\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0011 \n",
            "--------------------------------------------------\n",
            "Epoch: 75  Train Loss: 0.0007  Valid Loss: 0.0011\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0011 \n",
            "--------------------------------------------------\n",
            "Epoch: 76  Train Loss: 0.0007  Valid Loss: 0.0011\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0011 \n",
            "--------------------------------------------------\n",
            "Epoch: 77  Train Loss: 0.0007  Valid Loss: 0.0011\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0010 \n",
            "--------------------------------------------------\n",
            "Epoch: 78  Train Loss: 0.0007  Valid Loss: 0.0010\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0010 \n",
            "--------------------------------------------------\n",
            "Epoch: 79  Train Loss: 0.0007  Valid Loss: 0.0010\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0010 \n",
            "--------------------------------------------------\n",
            "Epoch: 80  Train Loss: 0.0007  Valid Loss: 0.0010\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0008 \n",
            "--------------------------------------------------\n",
            "Epoch: 81  Train Loss: 0.0007  Valid Loss: 0.0008\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0008 at epoch 81/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0011 \n",
            "--------------------------------------------------\n",
            "Epoch: 82  Train Loss: 0.0007  Valid Loss: 0.0011\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0010 \n",
            "--------------------------------------------------\n",
            "Epoch: 83  Train Loss: 0.0006  Valid Loss: 0.0010\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0010 \n",
            "--------------------------------------------------\n",
            "Epoch: 84  Train Loss: 0.0006  Valid Loss: 0.0010\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0009 \n",
            "--------------------------------------------------\n",
            "Epoch: 85  Train Loss: 0.0007  Valid Loss: 0.0009\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0010 \n",
            "--------------------------------------------------\n",
            "Epoch: 86  Train Loss: 0.0007  Valid Loss: 0.0010\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0009 \n",
            "--------------------------------------------------\n",
            "Epoch: 87  Train Loss: 0.0006  Valid Loss: 0.0009\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0009 \n",
            "--------------------------------------------------\n",
            "Epoch: 88  Train Loss: 0.0006  Valid Loss: 0.0009\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0009 \n",
            "--------------------------------------------------\n",
            "Epoch: 89  Train Loss: 0.0006  Valid Loss: 0.0009\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0010 \n",
            "--------------------------------------------------\n",
            "Epoch: 90  Train Loss: 0.0006  Valid Loss: 0.0010\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0008 \n",
            "--------------------------------------------------\n",
            "Epoch: 91  Train Loss: 0.0006  Valid Loss: 0.0008\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0008 at epoch 91/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0010 \n",
            "--------------------------------------------------\n",
            "Epoch: 92  Train Loss: 0.0006  Valid Loss: 0.0010\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0010 \n",
            "--------------------------------------------------\n",
            "Epoch: 93  Train Loss: 0.0006  Valid Loss: 0.0010\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0009 \n",
            "--------------------------------------------------\n",
            "Epoch: 94  Train Loss: 0.0006  Valid Loss: 0.0009\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0008 \n",
            "--------------------------------------------------\n",
            "Epoch: 95  Train Loss: 0.0006  Valid Loss: 0.0008\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0008 at epoch 95/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0009 \n",
            "--------------------------------------------------\n",
            "Epoch: 96  Train Loss: 0.0006  Valid Loss: 0.0009\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0008 \n",
            "--------------------------------------------------\n",
            "Epoch: 97  Train Loss: 0.0006  Valid Loss: 0.0008\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0008 at epoch 97/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0007 \n",
            "--------------------------------------------------\n",
            "Epoch: 98  Train Loss: 0.0005  Valid Loss: 0.0007\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0007 at epoch 98/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0008 \n",
            "--------------------------------------------------\n",
            "Epoch: 99  Train Loss: 0.0005  Valid Loss: 0.0008\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0009 \n",
            "--------------------------------------------------\n",
            "Epoch: 100  Train Loss: 0.0006  Valid Loss: 0.0009\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0008 \n",
            "--------------------------------------------------\n",
            "Epoch: 101  Train Loss: 0.0005  Valid Loss: 0.0008\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0009 \n",
            "--------------------------------------------------\n",
            "Epoch: 102  Train Loss: 0.0006  Valid Loss: 0.0009\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0009 \n",
            "--------------------------------------------------\n",
            "Epoch: 103  Train Loss: 0.0006  Valid Loss: 0.0009\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0007 \n",
            "--------------------------------------------------\n",
            "Epoch: 104  Train Loss: 0.0005  Valid Loss: 0.0007\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0007 at epoch 104/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0008 \n",
            "--------------------------------------------------\n",
            "Epoch: 105  Train Loss: 0.0005  Valid Loss: 0.0008\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0008 \n",
            "--------------------------------------------------\n",
            "Epoch: 106  Train Loss: 0.0005  Valid Loss: 0.0008\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0008 \n",
            "--------------------------------------------------\n",
            "Epoch: 107  Train Loss: 0.0005  Valid Loss: 0.0008\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0007 \n",
            "--------------------------------------------------\n",
            "Epoch: 108  Train Loss: 0.0005  Valid Loss: 0.0007\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0007 \n",
            "--------------------------------------------------\n",
            "Epoch: 109  Train Loss: 0.0005  Valid Loss: 0.0007\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0008 \n",
            "--------------------------------------------------\n",
            "Epoch: 110  Train Loss: 0.0005  Valid Loss: 0.0008\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0007 \n",
            "--------------------------------------------------\n",
            "Epoch: 111  Train Loss: 0.0005  Valid Loss: 0.0007\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0007 at epoch 111/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0008 \n",
            "--------------------------------------------------\n",
            "Epoch: 112  Train Loss: 0.0005  Valid Loss: 0.0008\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0008 \n",
            "--------------------------------------------------\n",
            "Epoch: 113  Train Loss: 0.0005  Valid Loss: 0.0008\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0009 \n",
            "--------------------------------------------------\n",
            "Epoch: 114  Train Loss: 0.0005  Valid Loss: 0.0009\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0007 \n",
            "--------------------------------------------------\n",
            "Epoch: 115  Train Loss: 0.0005  Valid Loss: 0.0007\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0008 \n",
            "--------------------------------------------------\n",
            "Epoch: 116  Train Loss: 0.0005  Valid Loss: 0.0008\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 117  Train Loss: 0.0005  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0006 at epoch 117/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0008 \n",
            "--------------------------------------------------\n",
            "Epoch: 118  Train Loss: 0.0004  Valid Loss: 0.0008\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0009 \n",
            "--------------------------------------------------\n",
            "Epoch: 119  Train Loss: 0.0004  Valid Loss: 0.0009\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0007 \n",
            "--------------------------------------------------\n",
            "Epoch: 120  Train Loss: 0.0004  Valid Loss: 0.0007\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0007 \n",
            "--------------------------------------------------\n",
            "Epoch: 121  Train Loss: 0.0004  Valid Loss: 0.0007\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0007 \n",
            "--------------------------------------------------\n",
            "Epoch: 122  Train Loss: 0.0005  Valid Loss: 0.0007\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0009 \n",
            "--------------------------------------------------\n",
            "Epoch: 123  Train Loss: 0.0005  Valid Loss: 0.0009\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0007 \n",
            "--------------------------------------------------\n",
            "Epoch: 124  Train Loss: 0.0004  Valid Loss: 0.0007\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0007 \n",
            "--------------------------------------------------\n",
            "Epoch: 125  Train Loss: 0.0004  Valid Loss: 0.0007\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0008 \n",
            "--------------------------------------------------\n",
            "Epoch: 126  Train Loss: 0.0005  Valid Loss: 0.0008\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0007 \n",
            "--------------------------------------------------\n",
            "Epoch: 127  Train Loss: 0.0004  Valid Loss: 0.0007\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 128  Train Loss: 0.0004  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0006 at epoch 128/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0007 \n",
            "--------------------------------------------------\n",
            "Epoch: 129  Train Loss: 0.0004  Valid Loss: 0.0007\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0007 \n",
            "--------------------------------------------------\n",
            "Epoch: 130  Train Loss: 0.0004  Valid Loss: 0.0007\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 131  Train Loss: 0.0004  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0008 \n",
            "--------------------------------------------------\n",
            "Epoch: 132  Train Loss: 0.0004  Valid Loss: 0.0008\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 133  Train Loss: 0.0004  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0006 at epoch 133/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 134  Train Loss: 0.0004  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0007 \n",
            "--------------------------------------------------\n",
            "Epoch: 135  Train Loss: 0.0004  Valid Loss: 0.0007\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0007 \n",
            "--------------------------------------------------\n",
            "Epoch: 136  Train Loss: 0.0004  Valid Loss: 0.0007\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0007 \n",
            "--------------------------------------------------\n",
            "Epoch: 137  Train Loss: 0.0004  Valid Loss: 0.0007\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0008 \n",
            "--------------------------------------------------\n",
            "Epoch: 138  Train Loss: 0.0004  Valid Loss: 0.0008\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0007 \n",
            "--------------------------------------------------\n",
            "Epoch: 139  Train Loss: 0.0004  Valid Loss: 0.0007\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0007 \n",
            "--------------------------------------------------\n",
            "Epoch: 140  Train Loss: 0.0004  Valid Loss: 0.0007\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0007 \n",
            "--------------------------------------------------\n",
            "Epoch: 141  Train Loss: 0.0004  Valid Loss: 0.0007\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0008 \n",
            "--------------------------------------------------\n",
            "Epoch: 142  Train Loss: 0.0004  Valid Loss: 0.0008\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 143  Train Loss: 0.0004  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0006 at epoch 143/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0008 \n",
            "--------------------------------------------------\n",
            "Epoch: 144  Train Loss: 0.0004  Valid Loss: 0.0008\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0007 \n",
            "--------------------------------------------------\n",
            "Epoch: 145  Train Loss: 0.0004  Valid Loss: 0.0007\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 146  Train Loss: 0.0004  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 147  Train Loss: 0.0004  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 148  Train Loss: 0.0003  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0005 \n",
            "--------------------------------------------------\n",
            "Epoch: 149  Train Loss: 0.0003  Valid Loss: 0.0005\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0005 at epoch 149/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0007 \n",
            "--------------------------------------------------\n",
            "Epoch: 150  Train Loss: 0.0004  Valid Loss: 0.0007\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 151  Train Loss: 0.0003  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0005 \n",
            "--------------------------------------------------\n",
            "Epoch: 152  Train Loss: 0.0003  Valid Loss: 0.0005\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0005 at epoch 152/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0007 \n",
            "--------------------------------------------------\n",
            "Epoch: 153  Train Loss: 0.0003  Valid Loss: 0.0007\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 154  Train Loss: 0.0004  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0008 \n",
            "--------------------------------------------------\n",
            "Epoch: 155  Train Loss: 0.0003  Valid Loss: 0.0008\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 156  Train Loss: 0.0004  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 157  Train Loss: 0.0003  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0007 \n",
            "--------------------------------------------------\n",
            "Epoch: 158  Train Loss: 0.0004  Valid Loss: 0.0007\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0007 \n",
            "--------------------------------------------------\n",
            "Epoch: 159  Train Loss: 0.0003  Valid Loss: 0.0007\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 160  Train Loss: 0.0003  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 161  Train Loss: 0.0003  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 162  Train Loss: 0.0003  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 163  Train Loss: 0.0003  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0007 \n",
            "--------------------------------------------------\n",
            "Epoch: 164  Train Loss: 0.0003  Valid Loss: 0.0007\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0005 \n",
            "--------------------------------------------------\n",
            "Epoch: 165  Train Loss: 0.0003  Valid Loss: 0.0005\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0005 at epoch 165/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0005 \n",
            "--------------------------------------------------\n",
            "Epoch: 166  Train Loss: 0.0003  Valid Loss: 0.0005\n",
            "--------------------------------------------------\n",
            "\n",
            "Minimum Validation Loss of 0.0005 at epoch 166/200\n",
            "Model Saved\n",
            "\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 167  Train Loss: 0.0003  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 168  Train Loss: 0.0003  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0005 \n",
            "--------------------------------------------------\n",
            "Epoch: 169  Train Loss: 0.0003  Valid Loss: 0.0005\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 170  Train Loss: 0.0003  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 171  Train Loss: 0.0003  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 172  Train Loss: 0.0003  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 173  Train Loss: 0.0003  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0007 \n",
            "--------------------------------------------------\n",
            "Epoch: 174  Train Loss: 0.0003  Valid Loss: 0.0007\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0005 \n",
            "--------------------------------------------------\n",
            "Epoch: 175  Train Loss: 0.0003  Valid Loss: 0.0005\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0005 \n",
            "--------------------------------------------------\n",
            "Epoch: 176  Train Loss: 0.0003  Valid Loss: 0.0005\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 177  Train Loss: 0.0003  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 178  Train Loss: 0.0003  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0005 \n",
            "--------------------------------------------------\n",
            "Epoch: 179  Train Loss: 0.0003  Valid Loss: 0.0005\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0005 \n",
            "--------------------------------------------------\n",
            "Epoch: 180  Train Loss: 0.0003  Valid Loss: 0.0005\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 181  Train Loss: 0.0003  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0005 \n",
            "--------------------------------------------------\n",
            "Epoch: 182  Train Loss: 0.0003  Valid Loss: 0.0005\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0005 \n",
            "--------------------------------------------------\n",
            "Epoch: 183  Train Loss: 0.0003  Valid Loss: 0.0005\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 184  Train Loss: 0.0003  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 185  Train Loss: 0.0003  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 186  Train Loss: 0.0003  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 187  Train Loss: 0.0003  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0005 \n",
            "--------------------------------------------------\n",
            "Epoch: 188  Train Loss: 0.0003  Valid Loss: 0.0005\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 189  Train Loss: 0.0003  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0005 \n",
            "--------------------------------------------------\n",
            "Epoch: 190  Train Loss: 0.0003  Valid Loss: 0.0005\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0005 \n",
            "--------------------------------------------------\n",
            "Epoch: 191  Train Loss: 0.0002  Valid Loss: 0.0005\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 192  Train Loss: 0.0002  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0005 \n",
            "--------------------------------------------------\n",
            "Epoch: 193  Train Loss: 0.0003  Valid Loss: 0.0005\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0005 \n",
            "--------------------------------------------------\n",
            "Epoch: 194  Train Loss: 0.0002  Valid Loss: 0.0005\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 195  Train Loss: 0.0003  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 196  Train Loss: 0.0003  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0005 \n",
            "--------------------------------------------------\n",
            "Epoch: 197  Train Loss: 0.0002  Valid Loss: 0.0005\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 198  Train Loss: 0.0003  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0006 \n",
            "--------------------------------------------------\n",
            "Epoch: 199  Train Loss: 0.0002  Valid Loss: 0.0006\n",
            "--------------------------------------------------\n",
            "Valid Steps: 13/13  Loss: 0.0005 \n",
            "--------------------------------------------------\n",
            "Epoch: 200  Train Loss: 0.0002  Valid Loss: 0.0005\n",
            "--------------------------------------------------\n",
            "Training Complete\n",
            "Total Elapsed Time : 11495.298874616623 s\n"
          ]
        }
      ],
      "source": [
        "torch.autograd.set_detect_anomaly(True)\n",
        "network = Network()\n",
        "network.cuda()    \n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.AdamW(network.parameters(), lr=0.0001)\n",
        "\n",
        "loss_min = np.inf\n",
        "num_epochs = 200\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(1,num_epochs+1):\n",
        "    \n",
        "    loss_train = 0\n",
        "    loss_valid = 0\n",
        "    running_loss = 0\n",
        "    \n",
        "    network.train()\n",
        "    for step in range(1,len(train_loader)+1):\n",
        "    \n",
        "        images, landmarks = next(iter(train_loader))\n",
        "        \n",
        "        images = images.cuda()\n",
        "        landmarks = landmarks.view(landmarks.size(0),-1).cuda() \n",
        "        \n",
        "        predictions = network(images)\n",
        "        \n",
        "        # clear all the gradients before calculating them\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # find the loss for the current step\n",
        "        loss_train_step = criterion(predictions, landmarks)\n",
        "        \n",
        "        # calculate the gradients\n",
        "        loss_train_step.backward()\n",
        "        \n",
        "        # update the parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        loss_train += loss_train_step.item()\n",
        "        running_loss = loss_train/step\n",
        "        \n",
        "        print_overwrite(step, len(train_loader), running_loss, 'train')\n",
        "        \n",
        "    network.eval() \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for step in range(1,len(valid_loader)+1):\n",
        "            \n",
        "            images, landmarks = next(iter(valid_loader))\n",
        "        \n",
        "            images = images.cuda()\n",
        "            landmarks = landmarks.view(landmarks.size(0),-1).cuda()\n",
        "        \n",
        "            predictions = network(images)\n",
        "\n",
        "            # find the loss for the current step\n",
        "            loss_valid_step = criterion(predictions, landmarks)\n",
        "\n",
        "            loss_valid += loss_valid_step.item()\n",
        "            running_loss = loss_valid/step\n",
        "\n",
        "            print_overwrite(step, len(valid_loader), running_loss, 'valid')\n",
        "    \n",
        "    loss_train /= len(train_loader)\n",
        "    loss_valid /= len(valid_loader)\n",
        "    \n",
        "    print('\\n--------------------------------------------------')\n",
        "    print('Epoch: {}  Train Loss: {:.4f}  Valid Loss: {:.4f}'.format(epoch, loss_train, loss_valid))\n",
        "    print('--------------------------------------------------')\n",
        "    \n",
        "    if loss_valid < loss_min:\n",
        "        loss_min = loss_valid\n",
        "        torch.save(network.state_dict(), '/content/face_landmarks.pth') \n",
        "        print(\"\\nMinimum Validation Loss of {:.4f} at epoch {}/{}\".format(loss_min, epoch, num_epochs))\n",
        "        print('Model Saved\\n')\n",
        "     \n",
        "print('Training Complete')\n",
        "print(\"Total Elapsed Time : {} s\".format(time.time()-start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YciYnPDUevd"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    best_network = Network()\n",
        "    best_network.cuda()\n",
        "    best_network.load_state_dict(torch.load('/content/face_landmarks.pth')) \n",
        "    best_network.eval()\n",
        "    \n",
        "    images, landmarks = next(iter(valid_loader))\n",
        "    \n",
        "    images = images.cuda()\n",
        "    landmarks = (landmarks + 0.5) * 512\n",
        "\n",
        "    predictions = (best_network(images).cpu() + 0.5) * 512\n",
        "    predictions = predictions.view(-1,70,2)\n",
        "    \n",
        "    plt.figure(figsize=(10,40))\n",
        "    \n",
        "    for img_num in range(8):\n",
        "        plt.subplot(8,1,img_num+1)\n",
        "        plt.imshow(images[img_num].cpu().numpy().transpose(1,2,0).squeeze(), cmap='gray')\n",
        "        plt.scatter(predictions[img_num,:,0], predictions[img_num,:,1], c = 'r', s = 5)\n",
        "        plt.scatter(landmarks[img_num,:,0], landmarks[img_num,:,1], c = 'g', s = 5)\n",
        "\n",
        "print('Total number of test images: {}'.format(len(valid_dataset)))\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"Elapsed Time : {}\".format(end_time - start_time)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PTncqwW3mAT",
        "outputId": "9b44c66f-af63-4080-9377-aea385a8b56c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyopencl\n",
            "  Downloading pyopencl-2022.2.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (932 kB)\n",
            "\u001b[K     |████████████████████████████████| 932 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyopencl) (1.21.6)\n",
            "Collecting platformdirs>=2.2.0\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Collecting pytools>=2021.2.7\n",
            "  Downloading pytools-2022.1.12.tar.gz (70 kB)\n",
            "\u001b[K     |████████████████████████████████| 70 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.7/dist-packages (from pytools>=2021.2.7->pyopencl) (4.1.1)\n",
            "Building wheels for collected packages: pytools\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2022.1.12-py2.py3-none-any.whl size=65034 sha256=4daee828aadbe55d679b6412cbd6d2842e0e74a98a11c9ed7c9fb448bd6709f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/5e/9e/76d7430e116b7cab0016fbabb26b896daae1946a3f7dea9915\n",
            "Successfully built pytools\n",
            "Installing collected packages: platformdirs, pytools, pyopencl\n",
            "Successfully installed platformdirs-2.5.2 pyopencl-2022.2.3 pytools-2022.1.12\n"
          ]
        }
      ],
      "source": [
        "pip install pyopencl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHqw7xJmlZUd",
        "outputId": "8f5fcfd9-94e0-4d17-a113-cd99b48cbed8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'url': 'https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rsb-weights/resnet101_a1h-36d3f2aa.pth',\n",
              " 'num_classes': 1000,\n",
              " 'input_size': (3, 224, 224),\n",
              " 'pool_size': (7, 7),\n",
              " 'crop_pct': 0.95,\n",
              " 'interpolation': 'bicubic',\n",
              " 'mean': (0.485, 0.456, 0.406),\n",
              " 'std': (0.229, 0.224, 0.225),\n",
              " 'first_conv': 'conv1',\n",
              " 'classifier': 'fc',\n",
              " 'architecture': 'resnet101'}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import timm \n",
        "from PIL import Image\n",
        "\n",
        "model = timm.create_model('resnet101', pretrained = True, in_chans = 1)\n",
        "model.default_cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LW5QB-1-R2Gf",
        "outputId": "774337a4-0def-45fc-aedc-5ef3fba9e403"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (act1): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (6): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (7): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (8): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (9): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (10): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (11): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (12): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (13): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (14): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (15): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (16): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (17): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (18): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (19): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (20): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (21): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (22): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2L11zscdZBc",
        "outputId": "e4245f00-02eb-40bc-c233-84e27e658d38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Linear(in_features=2048, out_features=1000, bias=True)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToEMfUUQxqo_",
        "outputId": "40bda5b4-a04d-473f-9326-9b28977c73cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-64.4161, -63.6883, -65.0479, -66.0958, -65.5833, -63.7724, -63.7647,\n",
              "         -63.6628, -63.5585, -64.6229, -65.4274, -64.7775, -64.8691, -64.3061,\n",
              "         -64.9955, -64.5582, -64.7826, -64.0101, -64.1025, -64.3574, -65.0566,\n",
              "         -64.8134, -65.4429, -64.0811, -64.8619, -64.4350, -64.2437, -65.0761,\n",
              "         -64.2564, -64.9170, -63.4673, -64.9045, -63.7331, -63.6884, -63.9417,\n",
              "         -63.6144, -63.1337, -63.8029, -64.3132, -62.5463, -64.5138, -64.4733,\n",
              "         -63.9953, -63.3244, -64.1258, -63.7107, -64.7654, -63.6337, -63.9827,\n",
              "         -64.1317, -63.9255, -62.6409, -64.4538, -64.3404, -64.1453, -65.0583,\n",
              "         -64.4052, -64.8787, -64.0751, -65.1803, -64.0521, -63.9734, -64.3587,\n",
              "         -63.5446, -64.6168, -65.3352, -65.1728, -64.8057, -65.0375, -64.4126,\n",
              "         -64.5633, -63.8818, -65.2910, -65.0121, -65.2352, -64.0844, -63.9911,\n",
              "         -64.3636, -64.7906, -63.3014, -65.1168, -65.5327, -64.1934, -64.4719,\n",
              "         -63.6086, -63.6207, -63.9355, -62.6978, -63.6241, -64.4759, -64.5254,\n",
              "         -64.6244, -65.1893, -63.5046, -63.7655, -65.7475, -64.0548, -64.4949,\n",
              "         -65.0201, -63.8056, -65.1121, -64.9979, -64.6885, -63.6339, -63.3463,\n",
              "         -64.1389, -64.3025, -64.9009, -65.0453, -64.6728, -65.1415, -65.5059,\n",
              "         -62.9208, -62.3518, -62.9565, -65.0956, -64.2780, -64.7435, -63.4117,\n",
              "         -64.4072, -64.0651, -63.5322, -63.0734, -63.6352, -61.6769, -62.8189,\n",
              "         -64.2956, -65.9287, -65.1122, -65.0302, -65.0659, -64.8714, -64.9254,\n",
              "         -65.0305, -64.2477, -64.8828, -64.2533, -65.2779, -65.1882, -65.7832,\n",
              "         -65.2402, -66.0565, -65.1900, -65.5709, -64.6607, -64.8470, -65.2140,\n",
              "         -65.7935, -65.1915, -64.9775, -62.6288, -61.0318, -65.0997, -65.0305,\n",
              "         -64.1161, -63.9935, -63.9013, -64.0023, -63.6487, -63.7073, -63.2597,\n",
              "         -62.7359, -63.4135, -62.8552, -63.4104, -63.7485, -63.8544, -63.9800,\n",
              "         -63.2839, -63.6476, -63.2677, -62.2834, -62.8547, -63.4913, -63.8200,\n",
              "         -64.6819, -63.4370, -63.2517, -63.4720, -63.8323, -63.3935, -64.1722,\n",
              "         -63.4201, -63.9015, -63.7691, -64.0247, -63.7210, -64.0905, -64.4075,\n",
              "         -63.8608, -64.5958, -64.2377, -64.0337, -63.9350, -65.1346, -63.2611,\n",
              "         -63.7265, -63.6862, -63.8048, -62.8864, -64.9060, -63.8969, -64.3834,\n",
              "         -63.6370, -64.7436, -64.0158, -63.8062, -64.2225, -63.1127, -63.5171,\n",
              "         -64.1341, -63.0289, -62.7236, -63.9446, -63.7299, -64.3585, -64.4501,\n",
              "         -63.4882, -64.4658, -63.5554, -64.4415, -63.9173, -64.0288, -62.3800,\n",
              "         -63.7705, -63.4409, -64.0901, -62.9755, -64.2444, -63.9771, -63.3256,\n",
              "         -62.5327, -63.4976, -64.4011, -63.0423, -62.9127, -63.3684, -62.7053,\n",
              "         -62.9152, -63.3659, -63.0353, -63.9163, -63.0904, -63.3067, -63.8092,\n",
              "         -63.6864, -63.0859, -63.9811, -63.2783, -62.6496, -62.7104, -63.2526,\n",
              "         -64.8960, -63.3469, -62.8657, -64.4674, -63.0433, -62.7446, -63.5857,\n",
              "         -63.3279, -64.2545, -64.0072, -63.9517, -62.9654, -63.0542, -62.2358,\n",
              "         -63.6168, -62.5179, -62.4978, -63.7313, -64.9311, -64.3042, -64.1717,\n",
              "         -63.7316, -64.7091, -64.2155, -63.7986, -64.0581, -64.4741, -64.4350,\n",
              "         -63.7796, -63.4117, -63.6194, -64.0117, -63.2278, -62.9485, -63.9145,\n",
              "         -64.5648, -65.0006, -65.1118, -65.2246, -64.7703, -64.1336, -64.1554,\n",
              "         -65.3968, -64.2670, -64.9157, -64.3815, -63.6491, -63.3388, -65.0979,\n",
              "         -64.3520, -64.3173, -64.3097, -64.7433, -63.8668, -62.8436, -64.4821,\n",
              "         -64.9881, -64.0110, -63.4080, -64.2925, -64.2354, -64.1780, -62.7850,\n",
              "         -64.4123, -63.8908, -65.0177, -65.6608, -64.4105, -65.5211, -64.7588,\n",
              "         -65.1324, -64.6506, -65.3436, -64.9059, -64.8994, -64.1523, -63.8226,\n",
              "         -64.6515, -63.4661, -63.5296, -63.6357, -63.4014, -63.3260, -63.2930,\n",
              "         -64.5698, -63.8238, -62.2832, -65.2021, -64.9150, -62.8963, -64.2339,\n",
              "         -64.4623, -64.2961, -63.7892, -63.3144, -65.2699, -63.9073, -65.0097,\n",
              "         -64.4540, -65.4402, -65.0328, -64.8698, -63.9754, -62.9861, -62.2971,\n",
              "         -63.4946, -62.8913, -62.5024, -63.5725, -63.2453, -63.2849, -62.9749,\n",
              "         -63.7606, -64.2077, -64.7551, -63.9228, -64.5232, -64.8641, -64.8919,\n",
              "         -64.0357, -63.4941, -63.6767, -63.7928, -64.1281, -65.2046, -63.6390,\n",
              "         -64.1403, -64.9265, -63.4801, -63.4533, -63.1119, -63.9228, -64.5096,\n",
              "         -64.1121, -64.8581, -63.7604, -64.0703, -64.0910, -63.4478, -63.1721,\n",
              "         -64.6481, -65.6727, -63.6653, -63.7642, -64.6540, -64.2219, -63.6653,\n",
              "         -63.9916, -65.0841, -61.8437, -64.3179, -66.0655, -66.3195, -64.8918,\n",
              "         -63.6643, -64.3142, -63.3285, -63.1275, -64.2126, -62.6850, -61.6210,\n",
              "         -63.3407, -63.3364, -62.4585, -64.6014, -63.6026, -63.8441, -63.0938,\n",
              "         -62.1893, -62.9932, -64.1908, -62.6660, -63.4933, -65.4570, -64.7376,\n",
              "         -63.1766, -61.4863, -64.3672, -65.5316, -64.8685, -63.1710, -63.9027,\n",
              "         -64.5044, -62.6975, -64.5127, -64.7247, -64.2804, -64.9979, -63.8262,\n",
              "         -63.8466, -64.4660, -63.8812, -64.0206, -64.1729, -64.3079, -61.9649,\n",
              "         -62.1543, -64.8750, -63.3243, -63.7625, -63.3983, -65.0871, -64.0081,\n",
              "         -64.0029, -62.1703, -62.4066, -64.9300, -62.9989, -65.2520, -62.0714,\n",
              "         -62.6048, -60.6751, -63.2657, -64.4247, -64.9341, -63.2136, -63.6476,\n",
              "         -61.5979, -62.6382, -63.1434, -62.5839, -62.8041, -64.4076, -63.2198,\n",
              "         -63.5697, -63.3392, -63.0826, -64.2459, -63.7977, -64.0399, -63.7924,\n",
              "         -65.3238, -64.7671, -63.7861, -63.4589, -63.3141, -63.0465, -63.9194,\n",
              "         -62.8589, -61.8957, -63.0596, -65.6976, -62.4537, -64.5460, -63.6171,\n",
              "         -65.3045, -64.7461, -62.1834, -65.2309, -62.8587, -62.0057, -63.5789,\n",
              "         -63.5172, -63.6566, -63.8172, -64.2787, -64.2869, -63.7861, -65.8610,\n",
              "         -64.2664, -63.4481, -63.7271, -62.4459, -62.0191, -63.5286, -63.7437,\n",
              "         -62.0746, -63.3931, -64.3522, -63.3876, -63.4814, -61.6605, -62.6059,\n",
              "         -64.9896, -63.3821, -64.1816, -63.1308, -63.7745, -64.4461, -64.1178,\n",
              "         -63.4093, -65.8323, -63.1135, -64.7361, -65.2456, -64.6385, -64.5547,\n",
              "         -63.7981, -65.5003, -61.3776, -61.9446, -63.6811, -63.6540, -62.6296,\n",
              "         -63.8865, -66.0332, -64.8252, -64.1470, -63.9495, -63.9611, -62.4329,\n",
              "         -64.2382, -65.6742, -64.4670, -63.3779, -64.3225, -61.2475, -63.8953,\n",
              "         -64.4494, -63.7439, -62.9988, -64.0806, -63.7224, -65.6429, -63.6663,\n",
              "         -63.4705, -62.5937, -63.8176, -62.5038, -63.1397, -62.6840, -64.4985,\n",
              "         -64.8076, -62.7082, -64.0834, -61.4708, -63.5248, -62.6676, -63.8358,\n",
              "         -63.5927, -62.6512, -63.2900, -63.0570, -62.1377, -64.5366, -61.1159,\n",
              "         -62.9256, -61.8377, -64.3864, -64.2628, -64.8545, -62.7234, -61.8150,\n",
              "         -65.0308, -61.5511, -63.7726, -64.8314, -63.8336, -62.1081, -64.3878,\n",
              "         -64.1866, -64.0864, -63.7147, -64.6110, -61.4800, -64.8164, -63.8081,\n",
              "         -63.4932, -64.2021, -64.0787, -63.1967, -63.0074, -61.8758, -64.0354,\n",
              "         -62.9999, -63.3673, -61.1461, -62.6042, -62.0085, -62.8208, -64.5207,\n",
              "         -64.0102, -64.7558, -64.8126, -61.9893, -64.2819, -65.8918, -64.0851,\n",
              "         -63.6197, -63.5709, -63.8040, -62.6520, -64.1022, -63.7795, -62.1959,\n",
              "         -62.2186, -63.7263, -64.0468, -65.0590, -61.6691, -63.2900, -61.7296,\n",
              "         -64.0891, -64.5787, -64.0287, -64.3084, -64.3763, -64.9266, -62.0137,\n",
              "         -64.4125, -63.5147, -63.1646, -63.5316, -62.8801, -64.1966, -63.7385,\n",
              "         -63.9097, -63.8114, -64.7796, -64.1544, -64.4836, -65.3100, -63.7593,\n",
              "         -63.0154, -62.8780, -63.9848, -64.7935, -63.9596, -62.4410, -64.0157,\n",
              "         -64.2142, -63.1622, -61.4380, -64.5408, -62.0201, -62.9273, -62.8380,\n",
              "         -63.7034, -63.7165, -63.6356, -65.1407, -63.1388, -62.6753, -65.0818,\n",
              "         -64.1740, -64.2601, -64.5767, -64.3901, -63.8281, -62.6885, -62.6123,\n",
              "         -62.0750, -65.1906, -63.4162, -60.9247, -63.1602, -65.4171, -62.0781,\n",
              "         -62.0195, -64.6633, -64.7399, -63.5143, -63.4543, -64.9058, -63.9590,\n",
              "         -62.4484, -63.9696, -63.7474, -63.3124, -62.7834, -64.7903, -64.6565,\n",
              "         -64.3245, -64.6820, -63.9039, -64.6229, -65.1935, -63.7122, -63.5510,\n",
              "         -64.3260, -63.1223, -63.3235, -64.9307, -62.4730, -63.5866, -64.2280,\n",
              "         -61.9216, -63.4236, -63.7962, -61.0924, -64.3764, -62.3978, -65.0419,\n",
              "         -64.0048, -63.3543, -63.3580, -63.1844, -62.8354, -62.0742, -64.3628,\n",
              "         -62.9227, -64.6591, -63.3516, -63.1970, -64.7987, -62.3554, -63.5150,\n",
              "         -61.0486, -63.7054, -64.0012, -63.9693, -63.7013, -63.2370, -65.4778,\n",
              "         -61.9406, -64.3343, -61.9362, -64.5986, -63.3778, -63.4109, -62.6427,\n",
              "         -63.0033, -61.6575, -63.2206, -63.2210, -62.9705, -65.2740, -62.5023,\n",
              "         -63.6266, -64.3301, -62.7574, -63.5858, -63.5914, -62.1661, -63.4275,\n",
              "         -63.3067, -61.4392, -64.0957, -64.8653, -64.8990, -63.4407, -63.8626,\n",
              "         -61.9076, -63.4406, -61.8205, -62.0272, -63.0158, -64.1352, -62.8610,\n",
              "         -62.2535, -61.9506, -63.5230, -64.1015, -63.0265, -62.7533, -62.8150,\n",
              "         -65.0621, -64.3784, -63.4488, -64.3629, -63.9436, -64.3188, -63.4061,\n",
              "         -63.3016, -64.3860, -62.8174, -62.0592, -63.8868, -64.3217, -63.2424,\n",
              "         -64.9733, -61.1893, -65.6152, -64.2904, -63.1306, -64.6834, -62.0802,\n",
              "         -64.2178, -65.1100, -65.5901, -62.5448, -62.5427, -62.6776, -64.9086,\n",
              "         -64.2978, -62.8619, -61.7301, -63.9722, -61.7760, -63.0545, -64.0537,\n",
              "         -64.2186, -64.0885, -62.4986, -63.2498, -62.1363, -63.6463, -64.9556,\n",
              "         -61.7086, -63.9381, -64.1654, -63.1922, -64.4937, -60.9572, -63.0555,\n",
              "         -64.5919, -63.2305, -62.2932, -62.1457, -61.9335, -63.3384, -64.4933,\n",
              "         -65.2131, -62.9066, -64.6806, -63.2077, -64.0536, -62.3197, -64.1206,\n",
              "         -62.6790, -63.3968, -63.8419, -64.9386, -63.3888, -64.0443, -65.0712,\n",
              "         -62.3367, -63.8814, -61.9984, -64.8537, -63.2821, -65.4663, -65.1840,\n",
              "         -63.9717, -62.1967, -64.0924, -64.9596, -61.5063, -62.3548, -64.2574,\n",
              "         -61.4688, -62.6378, -64.6560, -65.1672, -63.8878, -63.3524, -65.6545,\n",
              "         -63.1343, -65.2291, -62.9246, -63.5882, -63.6089, -63.9086, -64.6069,\n",
              "         -62.7379, -63.2136, -61.6969, -62.2218, -65.3017, -64.6430, -62.8282,\n",
              "         -62.9571, -65.2218, -64.2101, -64.6360, -63.6757, -65.3379, -62.7581,\n",
              "         -61.2440, -63.4818, -65.4481, -64.2633, -65.7864, -63.3022, -64.3601,\n",
              "         -63.0450, -62.5878, -64.1520, -63.4962, -63.0603, -64.1921, -63.0741,\n",
              "         -63.4517, -64.5374, -64.5241, -63.7333, -63.0999, -63.1781, -63.7416,\n",
              "         -63.4088, -63.5428, -64.5593, -62.6253, -64.9905, -63.7973, -64.1676,\n",
              "         -64.2313, -63.9002, -63.9669, -64.2273, -63.5399, -63.1232, -64.3568,\n",
              "         -64.9037, -65.3814, -63.4606, -63.6872, -64.5747, -64.1343, -64.0844,\n",
              "         -64.1602, -63.7769, -62.4759, -63.5112, -63.6429, -63.9874, -64.2264,\n",
              "         -64.9375, -63.7002, -62.6355, -65.0929, -64.4027, -64.6957, -63.3688,\n",
              "         -63.8418, -65.0767, -63.1929, -63.6345, -65.4293, -63.2101, -65.0085,\n",
              "         -64.8204, -65.6687, -64.4430, -66.3658, -64.8943, -64.9549, -66.4137,\n",
              "         -65.0917, -64.6340, -62.8624, -65.0693, -64.8416, -65.9526, -65.2547,\n",
              "         -62.3946, -63.2023, -63.8868, -63.2923, -65.5759, -65.0868, -65.2300,\n",
              "         -64.4988, -64.4958, -64.9047, -63.6467, -62.7804, -62.4109]],\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.randn(1,1,224,224)\n",
        "model(x)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}